{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "html_content=requests.get('https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=Python&txtLocation=')\n",
    "\n",
    "print(\" Enter the skills you are not familiar with :  \")\n",
    "unfamiliar_skills =input(\">>\")\n",
    "print(f'filtering out {unfamiliar_skills} ')\n",
    "\n",
    "def find_job():\n",
    "    soup = BeautifulSoup(html_content.text , 'html.parser')\n",
    "    jobs = soup.find_all('li' ,class_=\"clearfix job-bx wht-shd-bx\")\n",
    "    for index, job in enumerate(jobs):\n",
    "        posted_date=job.find('span',class_=\"sim-posted\").text\n",
    "        if 'few days' in posted_date:\n",
    "            company=job.find('h3', class_=\"joblist-comp-name\").text\n",
    "            skills=job.find('span', class_=\"srp-skills\").text\n",
    "            link=job.header.h2.a['href']\n",
    "            if unfamiliar_skills   not in skills: \n",
    "                with open(f'textfile/{index}.txt','w') as f:\n",
    "                    f.write(f'company name : {company.strip()} \\n')\n",
    "                    f.write(f'required skills : {skills.strip()}\\n')\n",
    "                    f.write(f'for more info :{link}')\n",
    "                print(f'file saved : {index}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_job()\n",
    "        delay_time=10\n",
    "        print(f'waiting for {delay_time}  minutes....')\n",
    "        time.sleep(delay_time*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELCOME TO ZAMEN.COM\n",
      "choose city from \"Lahore\" , \"Karachi\" and \"Faisalabad\" .\n",
      ">>faisalabad\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "print('WELCOME TO ZAMEN.COM')\n",
    "print('choose city from \"Lahore\" , \"Karachi\" and \"Faisalabad\" .')\n",
    "city=input(\">>\")\n",
    "lahore_content=requests.get('https://www.zameen.com/Homes/Lahore-1-1.html')\n",
    "karachi_content=requests.get('https://www.zameen.com/Homes/Karachi-2-1.html')\n",
    "faisalabad_content=requests.get('https://www.zameen.com/Homes/Faisalabad-16-1.html')\n",
    "\n",
    "# def find_plot_lahore():\n",
    "if city == 'lahore':\n",
    "    html_content = lahore_content\n",
    "elif city==  'karachi' :\n",
    "    html_content = karachi_content\n",
    "else:\n",
    "    html_content = faisalabad_content\n",
    "    \n",
    "soup = BeautifulSoup(html_content.text , 'html.parser')\n",
    "plots = soup.find_all('li', class_=\"ef447dde\")\n",
    "with open('excelfile.csv','w' ,  encoding='utf8', newline='') as f:\n",
    "        thewriter = csv.writer(f)\n",
    "        region=['','',city]\n",
    "        heading=['Price' ,'Address','Area','Link' ]\n",
    "        thewriter.writerow(region)\n",
    "        thewriter.writerow(heading)\n",
    "\n",
    "        for plot in plots:\n",
    "            price= plot.find('div', class_=\"_1e0ca152 _026d7bff\").text\n",
    "            link =plot.article.div.a['href']\n",
    "            a=plot.find('div', class_=\"_22b2f6ed\")\n",
    "            area=a.find('div', class_=\"_7ac32433\").text\n",
    "            address=plot.find('div' ,class_=\"_162e6469\").text\n",
    "            values=[price, address, area , \"https://www.zameen.com\"+link+\"\\n\\n\"]\n",
    "            thewriter.writerow(values)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
